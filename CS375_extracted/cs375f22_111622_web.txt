 cs --    cs   analysis of algorithms  professor eric aaron  lecture  m w pm  lecture meeting location davis   business   sa due monday nov    sa out today also due monday nov     ps-lookahead out today   please get started on it   ps due nov     project  out due pm monday nov     yes that's a lot due nov   would you prefer something  due earlier   project  grading update   please meet with me if you'd like prompt feedback on any part of  project how many of you  won't be here for  monday's class  cs --    how to make an algorithm not just a  little faster but a lot faster   making algorithms a little faster changing the leading  constant or handling special cases is good keep doing it   making algorithms a lot faster can be even better   we'll discuss one important technique dynamic programming   primarily used when there's a recursive definition  at the center of an  algorithm and it's slowing things down   dynamic programming speeds things up by getting ri d of redundant  work without changing the main ideas of the algorithm   can turn algos from exponential time into polynomial time  illustrative example  fibonacci numbers   consider divide-and-conquer and dynamic programming  approaches to calculating the fibonacci numbers   fibonacci definition   f   f     fn  fn-  fn- for n     straightforward top-down recursive approach  rfibonacci n     if n   or n   then return n    else return rfibonaccin-  rfibonaccin- note there are two base cases   having more than one base case  is not uncommon with recursive  definitions   cs --    even more illustrative example  fibonacci numbers   straightforward top-down recursive approach  rfibonacci n      if n   or n   then return n     else return rfibonaccin-  rfibonaccin-   where are its inefficiencies   one possible dynamic programming approach a memoized recursive   approach uses an auxiliary table to store results  mfibonaccin      how would we write a memoized  recursive fibonacci function this is an  exponential  algorithm see  clrs pg   for  some of the math  behind that and  see me for the rest  even more illustrative example  fibonacci numbers   memoized version of fibonacci method   example of a time-memory or time-space trade-off   what's the time complexity   what would a bottom-up fibonacci approach look like mfibonaccin    let f  n be a new array    f      if n      f      for j    n    fj  - or other sentinel    return mfib-auxfnmfib-auxfn   if fn      return fn    else    fn  mfib-auxfn-   mfib-auxfn-    return fn  cs --    even more illustrative example  fibonacci numbers   straightforward top-down recursive approach  rfibonacci n      if n   or n   then return n     else return rfibonacci n-  rfibonacci n-  even more efficient bottom-up approach  fibonaccin    f   f     for  i    n    fi  fi-  fi-    return fn   could we do even better in what ways in what ways is this more  efficient  what is the time complexity  of this method the space  complexity  even more illustrative example  fibonacci numbers   straightforward top-down recursive approach  rfibonacci n      if n   or n   then return n     else return rfibonacci n-  rfibonacci n- even more efficient  bottom-up approach  fibonaccin    f   f     for  i    n    temp  f  f    f  f f  temp    return temp in what ways is this more  efficient  what is the time complexity  of this method the space  complexity  cs --    dynamic programming   the inefficient fibonacci algorithms had a lot of recursive calls   with a lot of redundant work the same calculations were done many  times e g  calculate fib as part of calculating fib  dynamic programming techniques can be more efficient for  problems that have overlapping sub-problems   divide-and-conquer methods recursively solve sub-p roblems then  combine sub-solutions into a solution   when there are overlapping repeating sub-problem s some of this  work can be redundant   dynamic programming methods can solve each sub-pro blem once store  results in a table o lookup and use the table  for later solutions  for the most part  the efficient fibonacci methods used a characteristic  technique of dynamic programming   results stored in a table or similar used to im prove efficiency   dynamic programming solutions can be either top-down or  bottom-up   but most of the time in practice when people tal k about a dynamic  programming solution they mean a bottom-up solutio n   in general when looking for a dynamic programming  solution   try recursive top-down approach with overlapping sub-problems   consider a memoized version   then try bottom-up iterative approach based on s ub-problems   then try to improve on space complexity of botto m-up method  cs --    for the most  part    dynamic programming is often applied to optimization problems  to find a  solution with an optimal minimal or maximal value  often for optimization problems it is or seems  necessary to consider all subsets of a set    so if we're looking at a set of size n what's the time complexity of such an algorithm   characteristic structure for dynamic programming a lgorithms   overlapping subproblems as previously seen  optimal substructure  an optimal solution is built from the optimal sol utions of  subproblems  this makes total sense if you think about it for a while if there isn't redundant work in  the algo or if optimal solutions aren't based on o ptimal solutions to subproblems then  why would we store solutions to subproblems for the most  part    dynamic programming is often applied to optimization problems  to find a  solution with an optimal minimal or maximal value  often for optimization problems it is or seems  necessary to consider all subsets of a set    so if we're looking at a set of size n what's the time complexity of such an algorithm   characteristic structure for dynamic programming a lgorithms   overlapping subproblems as previously seen  optimal substructure  an optimal solution is built from the optimal sol utions of  subproblems   steps in developing a dynamic programming algorith m    characterize the structure of an optimal solution  in words    recursively define the value of an optimal soluti on    compute the value of an optimal solution from the bottom up    construct an optimal solution from computed information these are on  clrs pg    we'll focus on  steps  and   leading to step  this makes total sense if you think about it for a while if there isn't redundant work in  the algo or if optimal solutions aren't based on o ptimal solutions to subproblems then  why would we store solutions to subproblems cs --    sequences and subsequences   another category of problems involves sequences and  subsequences   definition   given sequence x  x  x   x m another sequence  z  z  z    z k is a subsequence of x if    there exists a strictly increasing sequence  iiik of  indices of x s t  for all j in   k x ij  z j  i e  elements of x preserving order   example  definition   if x  abacab and y  abba    then aa ab ba bb aba abb and  others are all subsequences of  both x and y i e  they are  common subsequences  cs --    longest common subsequence   if x  abcbdab and y  bdcaba then  bca is a common subsequence but not a longest  common subsequence lcs   bcba and bcab are both longest common  subsequences of x y   there is no common subsequence of length    the longest common subsequence problem    given x   x  x      xm and y  y  y     yn find a longest  common subsequence lcs of x and y    what's the brute force way to solve this what's its time  complexity and what can we do about that  dynamic programming to the rescue   the lcs problem seems like a candidate for a dynam ic programming  solution  does it look like a recursive definition of lcs wo uld be helpful hint  yes    is there optimal substructure can the lcs of two sequences x and y be  built from the lcs of subsequences divide and con quer   are there overlapping sub-problems are there redu ndant calculations in a  recursive solution   as part of a recursive  divide-and-conquer defini tion we'll refer to the  i'th prefix of a sequence  definition  notation  given a sequence x  x  x   xm the i'th  prefix for i in   m is x i x  x   x i  so in our notation see prev  slide x   x  x      xm  xmand  y  y  y     yn  yn cs --    lcs a recursive solution   let x  x x     xmand y  y y     ynbe sequences  and let z  z z     zkbe any lcs of x and y    how does z relate to lcss of x and y or to lcss of  prefixes of x and y   how does this lead to a recursive solution for the length of an  lcs what subproblems need to be solved  lcs a recursive solution   let x  x x     x mand y  y y     y nbe sequences  and let z  z z     z kbe any lcs of x and y    how does z relate to lcss of x and y or to lcss of  prefixes of x and y   case   if x m  y n then z k x m y nand z k-is an lcs of x m-and y n-  case   if x m  y n then if z k x mthen z is an lcs of x m-and y   case   if x m  y n then if z k y nthen z is an lcs of x and y n-  how does this lead to a recursive solution for the length of an  lcs what subproblems need to be solved do you see overlapping subproblems from this formul ation  cs --    lcs a recursive solution   next step recursively find the length of the longest common  subsequence of x y   how can we do that based on our three cases   case   if x m  y n then z k x m y nand z k-is an lcs of x m-and y n-  case   if x m  y n then if z k x mthen z is an lcs of x m-and y   case   if x m  y n then if z k y nthen z is an lcs of x and y n-  note we need to track lengths of lcss of various sub-problems   use cij to store the length of lcs of x i y jgoal compute cmn  what's the base case for this recursion  the recursion is over sequences what's  the smallest sequence we might consider  lcs a recursive solution   next step recursively find the length of the longest common  subsequence of x y   how can we do that based on our three cases   case   if x m  y n then z k x m y nand z k-is an lcs of x m-and y n-  case   if x m  y n then if z k x mthen z is an lcs of x m-and y   case   if x m  y n then if z k y nthen z is an lcs of x and y n-  note we need to track lengths of lcss of various sub-problems   use cij to store the length of lcs of x i y j  recursive formulation   base case cj   and ci   for all i j   recursive  step to compute cij where ij     if x i y j cij  ci-j-     if x i  y j cij  maxcij- ci-j goal compute cmn  this reflects  uses the three  subproblems noted above  cs --    lcs a recursive solution   recursively find the length of the lcs of x y   base case cj   and ci   for all i j   recursive  step to compute cij where ij     if x i yj cij  ci-j-     if x i  yj cij  maxcij- ci-j   straightforward recursive code   initialize ci  cj   for i in   m j i n   n   initialize cij  nil for i in   m j in   n   lcsi j  i j are indices  this is for a particular i j     if ci j  nil  could use other sentinel value          then if x i y j                     then ci j  lcsi- j-    one less of both xy                      else ci j  maxlcs i j- lcs i- j     return ci j i e  one less elt  of either x or y i e  one less elt  of both x and y  initialize c including  the base cases  for the most even more   recall steps to developing a dyn  prog  algorithm    characterize the structure of an optimal solution  in words    recursively define the value of an optimal soluti on    compute the value of an optimal solution from the bottom up    construct an optimal solution from computed information   we've done the first two  now   how to compute the value of an optimal solution i e  the length of a  longest common subsequence with bottom-up design i nstead of top- down recursion perhaps using a table to avoid red undant work    what additional information would support construc ting a solution an  actual longest common subsequence from the computati on of the  optimal value stay with the same basic ideas just expressed in a  different design  cs --    bottom-up computation of optimal lcs  value   need m-by-n matrix c to store lengths   to compute cij need values of ci-j- when  x i yj and  ci- j and ci j- when x iyj lcsx y  input sequences x y     m  lengthx     n  lengthy     for i   to m do  ci       in first col of each row     for j   to n  do  c j     in first row of each col     for i   to m do         for j   to n do     process row by row              if xi yjthen ci j  ci- j-                else ci j  max ci j- ci- j     return cm n what is the optimal  length the length  of an lcs of full  sequences  x and y what is the time complexity of this algorithm actually m-by-n to  include the  case too  recall our recursive definition    base case cj   and ci   for all i j  recursive  step to compute cij for ij    if xi yj cij  ci-j-    if xi  yj cij  maxcij- ci-j  bottom-up computation of an optimal lcs   to find an lcs also store which symbols indices of symbols  are actually part of the lcs as it's being built   i e   which table elements have optimal sub-probl em values   if x i y j  answer came from the upper left diagonal of curr ent element   if x iyjthe answer came from above or to the left whicheve r is larger  if equal we can choose above by convention  lcsx y     m  lengthx     n  lengthy     for i   to m do  ci       for j   to n  do  c j      for i   to m do         for j   to n do   if xi y j then ci j  ci- j-      bi j  upleft        else    if ci -  j   ci j -  then    ci j  ci -  j               bi j  up one less elt  of x    else ci  j  ci j -     bi j  left one less elt  of y i e  one less elt  of both x and y  i e   either x or y  cs --     lcs example  lcs of  x  abcbdab  and  y  bdcaba  the algorithm finds  an lcs bcba  are there others  and finally finding a solution from the values   that bottom-up method gives us the information from which  we can get an optimal value and the associated indices   to actually find  print the longest common subsequence  start at the bottom-left of the table and follow the arrows  print- lcs bxij    if i   or j   then return     if bij  upleft          then print-lcsbxi-j-                   print x i    else if bij  up          then print-lcsbxi-j     else print-lcsbxij- initial call has  i  m i e  lengthx  j  n lengthy    b is the arrow table from  the previous slide 