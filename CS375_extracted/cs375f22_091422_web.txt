cs   analysis of algorithms  professor eric aaron  lecture  m w pm  lecture meeting location davis   business   smaller assignment  due already   graded work will be returned to you in your submittedwork folder   i'll email the entire class when it's been returned   smaller assignment  out due sept     problem set  out due sept    for the semester please  assume all ps and sa deadlines  are pm on deadline day  whether or not it's explicitly  stated in lecture  cs --     business pt     project  out today    please read the full project assignment instructions are given there   please note project-specific lateness policy on assignment sheet   some key points about proj   deadline end of day pm on september    part of it asymptotic complexity analysis on methods in a java   class you're given the source code   part of it analyzing and conjecturing about asymptotic complexity  when you're given data from runtime performance not source code   project  is to be done in teams of  or    important by end of day saturday sept   one person from   each team should email me and everyone on the team to let me know  they're teaming up   if you'd like my help finding a team for you please let me know  see clrs  ch     pg  -  time complexity of   insertion sort   what's the time complexity of insertion sort   our default is to look at the worst-case complexity of   the algo on an input of size n  time complexity  from adding cost   times   so what's the   worst case complexity  in worst case tj  j each time  so tn is order of n  we'd say insertion sort   is an n algorithm  plug in tj  j   note summation  is same for c c  cs --     time complexity of   insertion sort   what's the time complexity of insertion sort   our default is to look at the worst-case complexity of   the algo on an input of size n  add up the   cost  times   for each row  what do we get  time complexity  from adding cost   times   so what's the best  case complexity  in best case tj   each  time so   this means insertion sort is linear in   the best case    but we don't consider it a linear algo  because that's not its worst case time  complexity  space complexity of   insertion sort   while we're at it what's the space complexity of insertion   sort   that is how much space is used beyond the storage for the input  cs --     space complexity of   insertion sort   while we're at it what's the space complexity of insertion   sort   that is how much space is used beyond the storage for the input   other than input a there are a   few variables for storage   j key i   so constant space complexity   and this is true in best case worst case and average case  space complexity constant  cs --     back to time complexity   so that counted   we just counted numbers of operations for best case and worst   case of insertion sort  well we kinda did those ci constants weren't super precise    how does that help us talk about which algorithms are faster than   others   big idea consider time complexity on large input sizes n   lots of algorithms are usable on small inputs   the algorithms that are faster on large inputs are the ones we're   going to consider fastest    but how do we define that for rigorous algorithm analysis  introduction to time complexity   analysis of algorithms  let's take the big-picture view  how in principle could we  measure the time efficiency of an algorithm  could use a timer or stopwatch or clock or calendar to   measure how fast a program is on a given size of input  called empirical analysis  but that doesn't really measure the algorithm speed  how much clock time passes is dependent on things other than just the   algorithm processor speed memory access speed etc    better idea count how many operations an algorithm does on   a given size of input as a measure of how long it takes  assume some unit of time for each operation  this gives a measure of time usage i e  speed that is dependent upon   the algorithm as written not external factors  cs --     introduction to time complexity   analysis of algorithms cont    but even that kind of counting depends on how an algorithm is   implemented  if  the insertion sort idea is implemented with even minor differences  operation count could change but the algorithm is the essentially the   same independent of minor coding details   we don't want to say the algorithm has different speeds just because of   many slightly different implementations    we want to discuss algorithm time complexity at a level a little   bit more abstract than just a literal count of operations  if somehow we could capture the essential character of how many   operations insertion sort takes    on input of a given size e g  an array of size n    without getting caught up in small details  asymptotic analysis    big-o notation   with insertion sort if we gloss over minor details we can see   the number of operations worst case is on the order of n  i e  it is cn  lower order terms   for some constant c    where n is the size of the input   definition an algorithm runs in time ofn read order of   fn means  there exist c   n   s t    for all n  n the running time of the algorithm is less than cfn  basically that means that for every input big enough the running   time is less than a constant times fn   this running time measure captures some essential   characteristic of an algorithm  on algorithms differ from on from on log n etc   cs --     cs --   asymptotic examples   in what big-o classes are the following   n    n  n for the next one we use the shorthand that an algorithm is in fn   ogn if the running time is fn  tn for some tn in ogn   similarly for ofn  ogn  or other arithmetic combinations    n lg n  on  o  on   formal definition describes what we intuitively  mean by not worrying about lower-order terms  common complexity measures and   how they relate to input sizes   algorithms are sometimes   described by their time  complexity  there are  logarithmic algorithms  quadratic algorithms  exponential algorithms  factorial algorithms  etc    to see which kind is  fastest see how these  functions grow with  increases in the input size  log n n  n          n    n                    e  e        e  e    conventional wisdom about big-o classes    if two algorithms are in different big-o classes then there seems to be  something substantially different about their speeds  even though for some small values of n an on algorithm could be   faster than an on algorithm   it is nonetheless true that n grows faster than n  thus an on algorithm is in a relevant sense inherently slower than an   on algorithm  important vocab see clrs pg   these functions of n have very different  orders of growth i e  how fast they grow as n gets larger   for an on algorithm called linear   doubling the input size does what to the running time  increasing input size by factor of  does what to running time   for an on algorithm quadratic   doubling the input size does what to the running time  increasing input size by factor of  does what to running time   for an on algorithm exponential   doubling the input size does what to the running time  cs --     