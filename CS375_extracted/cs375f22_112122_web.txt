cs   analysis of algorithms  professor eric aaron  lecture  m w pm  lecture meeting location davis   business   sa sa due already   full ps out due nov     no exercises beyond the lookahead   small modification to late problem set policy from syllabus  if you have  pss submitted more than  week late any additional pss   submitted more than  week late will be a  deduction   please turn in ps and ps on time   project  out due pm monday nov     ps grading update   project    will be out next monday nov     will be due no sooner than  weeks after that   intended team size  but talk to me if you'd prefer to work with a   smaller team size  cs --     for the most part   the efficient fibonacci methods used a characteristic   technique of dynamic programming  results stored in a table or similar used to improve efficiency   dynamic programming solutions can be either top-down or   bottom-up  but most of the time in practice when people talk about a dynamic   programming solution they mean a bottom-up solution    in general when looking for a dynamic programming  solution  try recursive top-down approach with overlapping sub-problems   consider a memoized version   then try bottom-up iterative approach based on sub-problems   then try to improve on space complexity of bottom-up method  for the most  part    dynamic programming is often applied to optimization problems to find a   solution with an optimal minimal or maximal value  often for optimization problems it is or seems necessary to consider all subsets of a set    so if we're looking at a set of size n what's the time complexity of such an algorithm   characteristic structure for dynamic programming algorithms   overlapping subproblems as previously seen   optimal substructure an optimal solution is built from the optimal solutions of   subproblems  this makes total sense if you think about it for a while if there isn't redundant work in  the algo or if optimal solutions aren't based on optimal solutions to subproblems then  why would we store solutions to subproblems   steps in developing a dynamic programming algorithm     characterize the structure of an optimal solution in words    recursively define the value of an optimal solution    compute the value of an optimal solution from the bottom up    construct an optimal solution from computed information  these are on  clrs pg     we'll focus on  steps  and   leading to step   cs --     cs --     bottom-up computation of optimal lcs   value   need m-by-n matrix c to store lengths   actually m-by-n to  include the  case too   to compute cij need values of ci-j- when xi  yj and   ci- j and ci j- when xi  yj   recall our recursive definition   base case cj   and ci   for all i j recursive  step to compute cij for ij    if xi  yj cij  ci-j-    if xi    yj cij  maxcij- ci-j   what is the time complexity of this algorithm   lcsx y  input sequences x y    m  lengthx    n  lengthy    for i   to m do  ci       in first col of each row    for j   to n  do  c j     in first row of each col    for i   to m do        for j   to n do     process row by row             if xi  yj then ci j  ci- j-               else ci j  max ci j- ci- j    return cm n   what is the optimal  length the length  of an lcs of full  sequences  x and y  cs --   bottom-up computation of an optimal lcs   to find an lcs also store which symbols indices of symbols   are actually part of the lcs as it's being built  i e   which table elements have optimal sub-problem values   if xi  yj  answer came from the upper left diagonal of current element i e  one less elt  of both x and y   if xi  yj the answer came from above or to the left whichever is larger   if equal we can choose above by convention  i e  either x or y  bi j  upleft  if xi  yj then ci j  ci- j-    if ci -  j   ci j -  then            else                   bi j  up one less elt  of x      ci j  ci -  j  else ci  j  ci j -   bi j  left one less elt  of y  lcsx y    m  lengthx    n  lengthy    for i   to m do  ci       for j   to n  do  c j      for i   to m do        for j   to n do   lcs example  lcs of  x  abcbdab and  y  bdcaba  the algorithm finds  an lcs bcba  are there others    cs --   and finally  finding a solution from the values   that bottom-up method gives us the information from which   we can get an optimal value and the associated indices   to actually find  print the longest common subsequence  start at the bottom-left of the table and follow the arrows  print- lcs bxij     if i   or j   then return    if bij  upleft         then print-lcsbxi-j-                  print xi    else if bij  up         then print-lcsbxi-j    else print-lcsbxij-  initial call has   i  m i e  lengthx  j  n lengthy     b is the arrow table from  the previous slide    graphs  see sec  b   a directed  graph b undirected graph   graphs commonly represent connections among related elements   an undirected graph g  ve is   a set v of vertices nodes and   so in undirected graphs edges are  unordered pairs of vertices whereas  in digraphs edges are ordered pairs    a set e of edges linked pairs of nodes                                                     which are bidirectional   a directed graph or digraph g  ve is   a set v of vertices nodes and   by convention in an undirected  graph g  ve we consider uv  and vu to be the same edge so at  most one of those pairs will be in e    a set e of unidirectional edges typically represented as arrows  note that   self-loops edges from a node to itself are possible   convention for algorithm analysis we may use v for v and e for e  more graph vocabulary  so we can talk  about more  graphs   graphs with the same number of vertices can have different numbers   of edges  what's the most edges a graph can have in terms of v  a sparse graph is one in which e is much less than v  a dense graph is one in which e is close to v in a digraph a path v v     vk forms a cycle if  v  vk and the path  contains at least one edge  see clrs pg       a cycle is simple if v v     vk are distinct   why not include v in this  a  f  d  b  g  e  c  h   a directed graph with no cycles is a directed acyclic graph or dag  cs --     read clrs sec   -   adjacency list representations   a graph can be represented as an adjacency list   for each vertex v there's a list of all nodes adjacent to v   represented as an array of v  n lists  a  d  b  f   complexity   storage space ov  e  c  e  example  an  undirected graph  a  b  c  d  e  f  b  a  b  a  c  e  d  c  e  f  f  d   for what kinds of graphs is this an efficient storage representation   what's the time complexity to find if an edge is in a graph  adjacency list representations   a graph can be represented as an adjacency list   for each vertex v there's a list of all nodes adjacent to v   represented as an array of v  n lists  a  d  b  f  c  e  example a digraph  for digraphs only outgoing edges are in e  thus in the lists  a  b  a  e  e  d  a  b  c  d  e  f  cs --     graphs adjacency matrix representations  there is no spoon next to anything   from the adjacency matrix   a graph can be represented as an adjacency matrix   a v-by-v matrix  for each pair ij of vertices entry ij in the  a  b  c   d  e  f  g  matrix is  if ij in e and  otherwise  a  d  f  b  g  c  e  example an undirected graph   complexity   storage space ov  a b  c d e f g                                                               what's the time complexity to find if an edge is in a graph  for directed graphs only outgoing edges are in e thus in the matrix  weighted graphs and shortest paths could be the album title  for a collaboration between xkcd and death cab for cutie   well it could be   weighted graphs and shortest paths   graphs can be weighted   given gve there is a weight  function w that maps each edge  in e to a real-valued weight   for weighted graphs an adjacency matrix can store the weight of an edge   in e rather than just  or    given such a w we say the weight of a path wp for p  v v   vk is the sum of the weights of the edges on that path i e  v v  v v  vk- vk   we then say the shortest path weight uv from vertex u to vertex v is   the least weight of any path in g from u to v   a shortest path from u to v is any path from u to v in g with that weight  cs --     shortest path problems   kinds of graph problems based on finding shortest paths by   convention presume weighted directed graphs  single-source shortest paths   various algorithms for cases of it e g  dijkstra   single-destination shortest paths   if we have a single-source shortest paths   algorithm how could we solve this   single-pair shortest path   how does this relate to the single-source variant   all-pairs shortest paths   we'll talk more about this soon    note to represent a shortest path in solving such a problem each vertex  is presumed to have a predecessor field which stores its predecessor on the  path being considered   properties of shortest paths   optimal substructure of shortest paths   is each sub-path of a shortest path itself a shortest path   what's the argument for  counter-argument to that   can a shortest path in a weighted graph have a cycle   be sure to consider graphs with negative edges which could have   negative weight cycles as well as graphs with positive weight  cycles  cs --     all-pairs shortest paths   the all-pairs shortest paths problem   given weighted graph gv e with no negative weight cycles   find the shortest path from u to v for every u v in v   solutions can be based on dynamic programming and an   adjacency matrix representation of g  recall adjacency matrix w contains weight of each edge in e   by convention diagonal of  w is all s   how might we break this down into sub-problems for a   recursive solution  all-pairs shortest paths   a vertex-based recursive solution   solve all-pairs shortest path problem in terms of the intermediate vertices   that can appear on any shortest path   intermediate vertex of a simple path p  v v  vz   is any vertex on p other than v or vz  a simple path is a path  with all distinct vertices   for graph g call vertices v    n and consider subsets   vk     k of v    then for any two vertices i j in v consider all paths from   i to j with intermediate vertices drawn only from vk   in particular consider  a shortest path p from i to j   with intermediate vertices in vk   what's the relationship between p and the set of   shortest paths from i to j with intermediate vertices in vk-  also is p a simple path how do we know one way or another  cs --     all-pairs shortest paths   a vertex-based recursive solution    we're still considering shortest path p from i to j with   intermediate vertices in vk  what's the relationship between p and the set of shortest paths from i to j   with intermediate vertices in vk-    depends on whether or not vertex k is an intermediate vertex   on path p  if not then p is also a shortest path i to j with intermediate vertices in vk-  if so then p can be broken down into sub-paths that are shortest paths with   intermediate vertices in vk-    one sub-path is from i to k the other is from k to j  how do we know we can decompose p that way i e  that both sub- paths are shortest paths using only vertices numbered up to k-   given this how could we recursively define the shortest path lengths   between all pairs of vertices  all-pairs shortest paths   a vertex-based recursive solution    we're still considering shortest path p from i to j with   intermediate vertices in vk  what's the relationship between p and the set of shortest paths from i to j   with intermediate vertices in vk-    depends on whether or not vertex k is an intermediate vertex   on path p  if not then p is also a shortest path i to j with intermediate vertices in vk-  if so then p can be broken down into sub-paths that are shortest paths with   intermediate vertices in vk-    one sub-path is from i to k the other is from k to j   altogether if w is the weights matrix and           is the shortest path  value from i to j using only intermediate vertices numbered up to k  ijd  k    cs --     cs --   by the way which one's warshall  floyd-warshall algorithm   bottom-up all-pairs shortest paths   floyd-warshall algorithm for all-pairs shortest paths the bottom-up   method based on this decomposition   computes matrices dk           where each         is the shortest path   ijd  k    k    ijd  value from i to j using only intermediate vertices numbered up to k  note this computes  shortest path values  not the paths  see  clrs pages -  about computing the  paths themselves    what does this algorithm return what makes that a useful return value   what is the running time of this algorithm  a floyd-warshall example  see clrs  ch      computes matrices dk           where each           k    k    ijd  ijd  is the shortest path value from i to j using only  intermediate vertices numbered up to k   what d matrices does it   compute for this  example graph    cs --   a floyd-warshall example   computes matrices dk           where each           k    ijd  k    ijd  is the shortest path value from i to j using only  intermediate vertices numbered up to k   what d matrices does it   compute for this  example graph    