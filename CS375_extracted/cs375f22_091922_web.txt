 cs --    cs   analysis of algorithms  professor eric aaron  lecture  m w pm  lecture meeting location davis   business   smaller assignment  returned already   let me know if there are problems accessing it   smaller assignment  due already   problem set  out due sept     project  due sept     please direct project-specific questions to me ra ther than to tas   questions about general concepts that show up on t he project e g   theta notation though rather than specifics can  go to tas   everyone was on a team as of yesterday   let me know if there are problems  concerns with team assignments please read the emailed  classwide comments  cs --    business pt     class will be cancelled monday sept     will be an optional make-up class later in the sem ester   let's go over sa exercise  f   if axyz and bxy what is axb  axb is by definition a set of ordered pairs  please be sure to use the  correct notation and concepts notation and semantics matter to cs  just ask your compiler  asymptotic analysis   big-o notation   with insertion sort if we gloss over minor details we can see  the number of operations worst case is on the order of n  i e  it is cn  lower order terms    for some constant c  where nis the size of the input   definition an algorithm runs in time ofn read order of  fn means   there exist c  n  s t    for all n n the running time of the algorithm is less than cfn   basically that means that for every input big e nough the running  time is less than a constant times fn  so we'd say insertion sort is on  cs --    asymptotic analysis   big-o notation   definition an algorithm runs in time ofn read order of  fn means   there exist c  n  s t    for all n n the running time of the algorithm is less than cfn   basically that means that for every input big e nough the running  time is less than a constant times fn   informal intuition big-o is about  upper bounds   if a runtime tn is ofn then for  big enough n tn is upper bounded by  cfn for some leading constant cdefn  repeated from prev  slide  note this figure from your textbook uses fn  for runtime and gn for the bounding function  but it's the same idea fn is ogn upper  bounded by cgn for all n n breaking down the phrase  big-o asymptotic complexity   major takeaways about big-o asymptotic complexity  complexity  it's about describing the  resource usage of an algorithm  asymptotic  it describes complexity based  on behavior on large input sizes n  small inputs aren't really the point  big-o  it's an upper bound on complexity  on large inputs in fact there's one major takeaway for each of the three words in t he  phrase  big-o asymptotic complexity  based on their meaning   it's best to work from the end of that phrase to th e beginning  big-o in this picture for large enough n that is n  n  fn is upper bounded by a  leading constant c times gn  cs --    asymptotic analysis   big-o notation   definition an algorithm runs in time ofn read order of  fn means   there exist c  n  s t    for all n n the running time of the algorithm is less than cfn   basically that means that for every input big e nough the running  time is less than a constant times fn   this runtime measure captures some  essential characteristic of an algorithm   o n algorithms differ from o n  from o nlog n etc    can talk about asymptotic complexity classes   we say insertion sort is in complexity class on defn  repeated from prev  slide  recall big-o is about upper bounds  conventional wisdom about big-o classes   if two algorithms are in different big-o classes then there seems to be  something substantially different about their speed s   even though for some small values of n an o n algorithm could be  faster than an on  algorithm   it is nonetheless true that  ngrows faster than n   thus an o n algorithm is in a relevant sense inherently slower than an  on  algorithm   for an on algorithm called linear   doubling the input size does what to the running t ime   increasing input size by factor of  does what t o running time   for an on  algorithm quadratic   doubling the input size does what to the running t ime   increasing input size by factor of  does what t o running time   for an o n algorithm exponential   doubling the input size does what to the running t ime important vocab see clrs pg   these functions  of nhave very different  orders of growth  i e  how fast they grow as ngets larger  cs --    common complexity measures and  how they relate to input sizes   algorithms are sometimes  described by their time  complexity  there are   logarithmic algorithms   quadratic algorithms   exponential algorithms   factorial algorithms   etc    to see which kind is  fastest see how these  functions grow with  increases in the input size                 e  e      e  e n log  n nnn   cs --    using the big-o definition   definition ogn   fn  exists c n  s t  forall nn  fn cgn   is each of the below statements true explain your answers    n    on    n - n  on    n  on    n  on     n  on    n lg n  olg n    n  o n   n  o n using the big-o definition   definition ogn   fn  exists c n  s t  forall nn  fn cgn   is each of the below statements true explain your answers    n    on    n - n  on    n  on    n  on     n  on    n lg n  olg n    n  o n   n  o npro tip on how to explain these  in general when explaining why an  existential exists statement is  true explicitly give some witness  values that make it true as part of  the explanation   here if a statement is true can   you give specific values for c n that make it true  cs --    big oh there's more notation   theta notation asymptotically tight bound   definition gn   fn  exists c c  n   s t  forall nn  cgn fn cgn  big oh there's more notation   theta notation asymptotically tight bound   definition gn   fn  exists c c  n   s t  forall nn  cgn fn cgn  reminder--defn of big-o ogn   fn  exists c n   s t  forall nn fn cgn   cs --    big oh there's more notation   theta notation asymptotically tight bound   definition gn   fn  exists c c  n   s t  forall nn  cgn fn cgn   big-omega notation asymptotic lower bound   definition gn   fn  exists c n   s t  forall nn cgn fn  reminder--defn of big-o ogn   fn  exists c n   s t  forall nn fn cgn  big oh there's more notation   theta notation asymptotically tight bound   definition gn   fn  exists c c  n  s t  forall nn   cgn fn cgn   big-omega notation asymptotic lower bound   definition gn   fn  exists c n  s t  forall nn  cgn fn   what is the relationship among big-o big-omega and theta  classes   cs --    a big-symbols theorem   definition gn   fn  exists c c  n  s t  forall nn   cgn fn cgn   definition gn   fn  exists c n  s t  forall nn  cgn fn  theorem  for any two functions fn and gn  fn  gn iff fn   ogn and fn  gn   using the  definitions   definition gn   fn  exists c c  n  s t  forall nn   cgn fn cgn   definition gn   fn  exists c n  s t  forall nn  cgn fn   is each of the below statements true    n    n    n    n    n - n  n    n - n  n    n  n     n  n    n   n   n   n cs --    conventions order of growth  to within a constant multiple   two different levels of detail can be useful with asymptotic complexity   formal definitions and detailed explanations   informal high-level understanding and explanation s   when informally talking about asymptotic complexit y we often talk about  the order of growth of runtime functions to within a leading constant  multiple   we don't say exactly what the leading constant cor n threshold is   order of growth of the highest order  dominant te rm is most important  in cs unless specified otherwise feel free  to use the informal high-level approach   cs --    log it  questions about exponents   when solving equations we may want to know the value of  an exponent   e g  in equation x  we might want to ask what value of xmakes  that true  how could we even phrase that question   the logarithm function lets us ask the question   so for x   we'd say x  log  read as log base  of    examples log    log    log      logarithms are exponents so rules of exponentiation apply   e g  log bmn  log bm log bnif bx mand by n   then bxb y bxy  mn 